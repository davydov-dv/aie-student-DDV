# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-04.csv`
- Размер: (25000 строк, 62 столбца)
- Целевая переменная: `target` (классы и их доли)
  - `0`:   0.9508
  - `1`:   0.0492
- Признаки: что за типы (числовые / категориальные-подобные, если есть)
  - Все признаки числовые (float64)

## 2. Protocol

- Разбиение: train/test (доли, `random_state`)
  - test_size=0.25, random_state=42, stratify=y
- Подбор: CV на train (сколько фолдов, что оптимизировали)
  - Использовался StratifiedKFold(n_splits=5, shuffle=True, random_state=42) для кросс-валидации
  - Оптимизировался roc_auc — ключевая метрика для бинарной задачи с дисбалансом.
- Метрики: accuracy, F1, ROC-AUC (и почему эти метрики уместны именно здесь)
  - Accuracy — общая точность, полезна для оценки “грубого” качества.
  - F1-score — важен из-за сильного дисбаланса классов (класс 1 — всего 4.92%).
  - ROC-AUC — основная метрика выбора модели. Показывает, насколько хорошо модель разделяет классы независимо от порога.

## 3. Models

Опишите, какие модели сравнивали и какие гиперпараметры подбирали.

Минимум:

- DummyClassifier (baseline) — стратегия most_frequent (всегда предсказывает класс 0).
- LogisticRegression (baseline из S05) — с масштабированием (StandardScaler), подбор `C` в [0.1, 1.0, 10.0], `solver`='lbfgs', `l1_ratio`=0.
- DecisionTreeClassifier (контроль сложности: `max_depth` + `min_samples_leaf` или `ccp_alpha`) подбор:   
  - `max_depth`: [None, 3, 5, 8],
  - `min_samples_leaf`: [1, 5, 10, 20],
  - `ccp_alpha`: [0.0, 0.001, 0.005, 0.01],
- RandomForestClassifier подбор:   
  - `max_depth`: [None, 6, 10],
  - `min_samples_leaf`: [1, 5, 10],
  - `max_features`: ["sqrt", 0.5],
- Один boosting (HistGradientBoosting) подбор:
  - `learning_rate`: [0.03, 0.05, 0.1],
  - `max_depth`: [2, 3, None],
  - `max_leaf_nodes`: [15, 31, 63],

Опционально:

- StackingClassifier (с CV-логикой) — ансамбль из моделей: `LogisticRegression`, `RandomForest`, `HistGradientBoosting` -> финальный классификатор — `LogisticRegression`. Обучение с CV=5.

## 4. Results

- Таблица/список финальных метрик на test по всем моделям

          accuracy  f1	    roc_auc	    model
      5	0.98160	  0.776699	0.906037	Stacking
      4	0.97984	  0.742857	0.904646	HistGradientBoosting
      3	0.97024	  0.567442	0.903547	RandomForest
      1	0.96256	  0.409091	0.840041	LogReg(scaled)
      2	0.96848	  0.588727	0.827972	DecisionTree
      0	0.95088	  0.000000	0.500000	Dummy(most_frequent)
- Победитель (по ROC-AUC или по согласованному критерию) и краткое объяснение
   - Победитель: Stacking

        - Лучший ROC-AUC = 0.90604
        - Высокая точность (accuracy = 0.9816) и хороший F1 (0.7767) — модель эффективно работает даже на редком классе.
        - Стэкинг позволил объединить силы разных алгоритмов: линейный (LR), деревья (RF) и градиентный бустинг (HGB), что дало прирост в качестве.

## 5. Analysis

- Устойчивость: что будет, если поменять `random_state` (хотя бы 5 прогонов для 1-2 моделей) – кратко
  - Проведено 5 прогонов с разными random_state для DecisionTree. Результаты:

                    accuracy     f1	    roc_auc	       model
                 2	0.96848	  0.588727	0.827972	DecisionTree
                14	0.96656	  0.560000	0.799189	DecisionTree
                12	0.96656	  0.560000	0.796046	DecisionTree
                11	0.96656	  0.560000	0.796025	DecisionTree
                13	0.96656	  0.560000	0.793563	DecisionTree

     - R0C-AUC для DecisionTree: 0.793 - 0.827 (разброс ~0.0337). Модели стабильны — небольшие изменения random_state не влияют существенно на качество. Это говорит о надёжности протокола и отсутствии переобучения.       
- Ошибки: confusion matrix для лучшей модели + комментарий
  - True Negative (TN) = 5935 — модель правильно предсказала негативный класс (0) в подавляющем большинстве случаев.
  - False Positive (FP) = 8 — очень мало ложных срабатываний (модель редко ошибается, предсказывая "1" там, где было "0").
  - False Negative (FN) = 107 — модель пропускает 107 положительных объектов (предсказывает "0", хотя было "1"). Это основная ошибка.
  - True Positive (TP) = 200 — модель успешно нашла 200 из 307 позитивных примеров (~65% recall).
  - Предпочитает не выдавать ложные срабатывания (FP=8), даже если это приводит к пропуску части позитивов (FN=107).
- Интерпретация: permutation importance (top-10/15) + выводы
  - Permutation importance отвечает на вопрос: “Если случайно перемешать один признак, насколько сильно ухудшится качество модели?” Если качество падает сильно – признак важен. Если почти не меняется – признак малозначим (для этой модели и этой метрики).
  - Самые важные признаки, которые удалось выявить: f54, f25, f58, f33, f04, f53, f38, f47, f41, f08, f50, f36, f07, f13, f43
  - Признак f54 доминирует - его перемешивание снижает ROC-AUC почти на 1.75%, что говорит о его критической роли в прогнозировании целевой переменной.
  - Также сильно влияют f25, f58 - перемешивание снижает ROC-AUC ~0.014 и ~0.011
  - Следом идет группы признаков (f33, f04, f53), (f38, f47, f41, f08), (f50, f36, f07, f13, f43) - по значимости примерно равны между собой, вероятно группы описывают схожие свойства
  - Модель не переобучена на шум — большинство признаков имеют низкую важность.

## 6. Conclusion

3-6 коротких тезисов: что вы поняли про деревья/ансамбли и про честный ML-протокол.
  - Ансамбли значительно превосходят одиночные модели: стэкинг из логистической регрессии, случайного леса и градиентного бустинга показал лучшее качество по всем метрикам, что подтверждает силу объединения разнородных алгоритмов.
  - Гиперпараметры критичны для деревьев: даже небольшие изменения max_depth, min_samples_leaf или learning_rate сильно влияют на качество — без тщательной настройки деревья быстро переобучаются или недообучаются.
  - ROC-AUC и F1 важнее accuracy при дисбалансе: базовая модель Dummy достигает 95% accuracy, но бесполезна на практике — только комплексная оценка (включая ROC-AUC и F1) отражает реальную способность модели работать с редким классом.
  - Честный протокол требует строгой изоляции test-выборки: все решения (подбор гиперпараметров, выбор модели) должны приниматься только на train/CV, а финальная оценка — один раз на невиданном test. Это единственный способ получить достоверную оценку качества.
  - Интерпретация важна даже в black-box моделях: permutation importance позволила убедиться, что модель опирается на осмысленные признаки, а не на шум — это ключевой элемент доверия к результатам.
