# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (12 000 строк, 9 столбцов)
- Признаки: все числовые (float64)
- Пропуски: нет
- "Подлости" датасета: признаки в сильно разных шкалах, наличие шумовых переменных, компактные кластеры

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (8 000 строк, 4 столбца)
- Признаки: все числовые (float64)
- Пропуски: нет
- "Подлости" датасета: нелинейная структура кластеров, явный шумовой признак (z_noise), выбросы

### 1.3 Dataset C

- Файл: `S07-hw-dataset-04.csv`
- Размер:  (10 000 строк, 33 столбца после препроцессинга)
- Признаки:  2 категориальных (cat_a, cat_b), остальные — числовые
- Пропуски:  есть (~1.7–2.2% в числовых признаках)
- "Подлости" датасета: высокая размерность после One-Hot Encoding, пропуски, смешанные типы признаков

### 1.3 Dataset D

- Файл: `S07-hw-dataset-03.csv`
- Размер: (15 000 строк, 5 столбца)
- Признаки: все числовые (float64)
- Пропуски: нет
- "Подлости" датасета: кластеры разной плотности + фоновый шум. Часто провоцирует ошибки выбора eps для DBSCAN.

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг: 
  - Числовые признаки: SimpleImputer(strategy='median') → StandardScaler()
  - Категориальные признаки: SimpleImputer(strategy='constant', fill_value='missing') → OneHotEncoder(handle_unknown='ignore')
  - Использован ColumnTransformer + Pipeline; PCA не применялся при обучении моделей (только для визуализации)
- Поиск гиперпараметров:
  - KMeans: k ∈ [5, 20], n_init=10, random_state=42
  - DBSCAN: eps ∈ [0.2, 3.5] с шагом, зависящим от датасета; min_samples ∈ [3, 6]
  - Agglomerative: k ∈ [4, 20], linkage ∈ ['ward', 'complete', 'average']
  - Выбор лучшего — по silhouette_score (для DBSCAN — только по non-noise точкам)
- Метрики: 
  - Для DBSCAN метрики считались только по non-noise объектам (labels != -1)
  - Использованы: silhouette_score, davies_bouldin_score, calinski_harabasz_score
- Визуализация: PCA(2D) с random_state=42 для всех датасетов

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

Минимум (для каждого датасета):

- KMeans (k подбирался в диапазоне)
- DBSCAN (eps, min_samples) — для датасетов 1 и 4
- AgglomerativeClustering (k, linkage) — для датасетов 1-4

## 4. Results


### 4.1 Dataset A
- Лучший метод и параметры: DBSCAN (eps=0.6, min_samples=6)
- Метрики:
  - silhouette_score = 0.382
  - davies_bouldin_score = 1.25
  - calinski_harabasz_score = 8456.1
  - Доля шума: ~1.2%
- Комментарий: DBSCAN выявил плотные группы без избыточного шума. В отличие от KMeans, не навязывает сферическую форму, что лучше соответствует структуре данных.

### 4.2 Dataset B

- Лучший метод и параметры: KMeans (k=16)
- Метрики:
  - silhouette_score = 0.284
  - davies_bouldin_score = 0.956
  - calinski_harabasz_score = 2329.4
- Комментарий: Несмотря на нелинейность и шум, KMeans обеспечил максимальное покрытие данных без маркировки как выбросов. DBSCAN помечал ~8.5% точек как шум, Agglomerative показал худший silhouette.

### 4.3 Dataset C

- Лучший метод и параметры: DBSCAN (eps=2.5, min_samples=6)
- Метрики:
  - silhouette_score = 0.443
  - davies_bouldin_score = 0.971
  - calinski_harabasz_score = 5329.5
  - Доля шума: ~9.1%
- Комментарий: Высокая размерность после OHE требует увеличенного eps. DBSCAN позволил найти естественные плотностные группы без фиксированного числа кластеров, в отличие от KMeans/Agglomerative.

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- KMeans "ломается" при нелинейных формах (датасет 2), разной плотности (датасет 3) и высокой размерности (датасет 4). Он предполагает компактные, сферические кластеры одинаковой плотности.
- DBSCAN выигрывает, когда кластеры имеют произвольную форму и плотность (датасеты 1 и 4), а также при наличии шума.
- Наибольшее влияние оказали: масштабирование (обязательно для KMeans/DBSCAN), наличие шумовых признаков, высокая размерность и пропуски (в датасете 4).

### 5.2 Устойчивость (обязательно для одного датасета)

- Проверка устойчивости проведена на датасете 1: 5 запусков KMeans (n_init=10) с разными random_state.
- Результаты: средний попарный ARI ≈ 0.92, NMI ≈ 0.90 → высокая устойчивость.
- Вывод: решение устойчиво, так как KMeans с n_init=10 почти всегда находит одну и ту же структуру, несмотря на случайную инициализацию.

### 5.3 Интерпретация кластеров

- Интерпретация проводилась через средние значения признаков в каждом кластере (на основе исходных данных до PCA).
- Например, в датасете 4 кластеры различались по комбинациям категориальных значений (cat_a, cat_b) и уровням числовых признаков (например, n01, n05).
- В датасете 1 кластеры четко разделялись по значениям f01, f02 — что подтверждалось визуализацией.

## 6. Conclusion

Silhouette_score не всегда достаточен — нужно учитывать долю шума, визуализацию и смысловую интерпретацию.
DBSCAN мощен при сложной геометрии, но чувствителен к выбору eps и может маркировать много точек как шум.
KMeans надежен при компактных кластерах, но легко «ломается» на нелинейных или разреженных данных.
Препроцессинг — ключевой этап: корректная обработка пропусков и категориальных признаков критична в unsupervised-задачах.
Устойчивость решений важна: даже при хорошем silhouette, решение может быть нестабильным без достаточного n_init или правильного метода.
PCA-визуализация помогает, но не заменяет количественную оценку.
Нет универсального метода: выбор алгоритма должен основываться на структуре данных, а не только на метриках.
